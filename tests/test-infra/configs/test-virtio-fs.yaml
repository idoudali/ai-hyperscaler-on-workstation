version: "1.0"
metadata:
  name: "test-hpc-virtio-fs"
  description: "Test cluster for virtio-fs host directory sharing validation"

global: {}

clusters:
  hpc:
    name: "test-hpc-virtio-fs"
    # Default cluster-level base image path (nodes can override with specialized images)
    # Relative paths will be resolved from the directory where the CLI is executed
    base_image_path: "build/packer/hpc-compute/hpc-compute/hpc-compute.qcow2"
    network:
      subnet: 192.168.190.0/24
      bridge: "virbr190"

    # Hardware acceleration configuration (x86_64 only)
    hardware:
      acceleration:
        enable_kvm: true           # Enable KVM hardware virtualization
        enable_nested: false       # Enable nested virtualization
        cpu_model: "host-passthrough"  # host, host-passthrough, host-model, qemu64
        cpu_features:              # Additional CPU features
          - "+vmx"                 # Intel VT-x virtualization
          - "+svm"                 # AMD-V virtualization
          - "+sse4.1"              # SSE 4.1 instructions
          - "+sse4.2"              # SSE 4.2 instructions
        numa_topology: null        # NUMA topology (auto-detect if null)
        cpu_topology:              # CPU topology settings
          sockets: 1
          cores: 2
          threads: 1
        performance:
          enable_hugepages: false  # Use hugepages for better memory performance
          hugepage_size: "2M"      # 2M or 1G hugepages
          cpu_pinning: false       # Pin vCPUs to physical CPUs
          memory_backing: "default" # default, hugepages, memfd

    controller:
      cpu_cores: 4
      memory_gb: 8
      disk_gb: 30
      ip_address: "192.168.190.10"
      # Use specialized controller image
      base_image_path: "build/packer/hpc-controller/hpc-controller/hpc-controller.qcow2"

      # Virtio-FS host directory sharing configuration
      virtio_fs_mounts:
        - tag: "datasets"
          host_path: "/tmp/test-virtio-fs-datasets"
          mount_point: "/mnt/host-datasets"
          readonly: false
        - tag: "containers"
          host_path: "/tmp/test-virtio-fs-containers"
          mount_point: "/mnt/host-containers"
          readonly: true

    # Single compute node for testing (optional for virtio-fs testing)
    compute_nodes:
      - cpu_cores: 2
        memory_gb: 4
        disk_gb: 20
        ip: "192.168.190.11"
        # Use specialized compute image
        base_image_path: "build/packer/hpc-compute/hpc-compute/hpc-compute.qcow2"
        # No PCIe passthrough or virtio-fs for compute nodes in this test

    slurm_config:
      partitions: ["debug"]
      default_partition: "debug"
      max_job_time: "1:00:00"

  # Cloud cluster required by schema but not used for virtio-fs testing
  cloud:
    name: "test-cloud-virtio-fs"
    base_image_path: "build/packer/cloud-base/cloud-base/cloud-base.qcow2"
    network:
      subnet: 192.168.191.0/24
      bridge: "virbr191"

    control_plane:
      cpu_cores: 2
      memory_gb: 4
      disk_gb: 20
      ip_address: "192.168.191.10"

    worker_nodes:
      cpu:
        - worker_type: "cpu"
          cpu_cores: 2
          memory_gb: 4
          disk_gb: 20
          ip: "192.168.191.11"

    kubernetes_config:
      cni: "calico"
      ingress: "nginx"
      storage_class: "local-path"
