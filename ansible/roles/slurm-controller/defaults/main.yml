---
# SLURM Controller Role - Default Variables
# This file contains default variables for the SLURM controller role
# These can be overridden in playbooks or inventory

# SLURM version
slurm_version: "21.08"

# Controller configuration
slurm_controller_name: "controller"

# Database configuration
slurm_database_host: "localhost"
slurm_database_port: 3306
slurm_database_name: "slurm_acct_db"
slurm_database_user: "slurm"

# MUNGE configuration
munge_key_path: "/etc/munge/munge.key"
munge_socket_path: "/var/run/munge/munge.socket.2"
munge_log_file: "/var/log/munge/munged.log"
munge_pid_file: "/var/run/munge/munged.pid"
munge_user: "munge"
munge_group: "munge"
munge_log_level: "3"
munge_credential_ttl: "300"
munge_port: 6818
munge_force_regenerate_key: false
munge_store_key_for_distribution: false
munge_create_key_backup: false
munge_key_backup_dir: "/opt/slurm/backup"

# PMIx configuration
pmix_enabled: true
pmix_ports: "12000-12999"

# SLURM MPI configuration
slurm_mpi_default: "pmix"
slurm_mpi_params: "ports=12000-12999"
slurm_mpi_timeout: 300

# SLURM PMIx specific configuration
slurm_pmix_server_addr: "localhost"
slurm_pmix_server_port: 15000
slurm_pmix_client_addr: "localhost"
slurm_pmix_client_port: 15001
slurm_pmix_timeout: 300
slurm_pmix_debug: 0

# PMIx resource management
slurm_pmix_resource_allocation: "dynamic"
slurm_pmix_memory_management: "auto"
slurm_pmix_cpu_affinity: "auto"

# PMIx communication
slurm_pmix_comm_protocol: "tcp"
slurm_pmix_message_size: 65536
slurm_pmix_buffer_size: 1048576

# PMIx security
slurm_pmix_security_mode: "none"
slurm_pmix_encryption: false
slurm_pmix_authentication: "munge"

# Resource management
gres_types: "gpu"
select_type: "select/cons_tres"
slurm_select_type_params: "CR_Core_Memory"

# SLURM scheduler configuration
slurm_scheduler_type: "sched/backfill"
slurm_scheduler_params: "bf_interval=5,bf_max_job_test=1000,bf_window=3600"

# Process tracking configuration
slurm_proctrack_type: "proctrack/cgroup"
slurm_task_plugin: "task/cgroup,task/affinity"
slurm_task_plugin_param: "Sched"

# Cluster configuration
slurm_cluster_name: "hpc-cluster"
slurm_controller_addr: "127.0.0.1"
slurm_compute_port: 6818

# Authentication and security
slurm_auth_type: "auth/munge"
slurm_crypto_type: "crypto/munge"

# Logging configuration
slurm_log_file: "/var/log/slurm/slurmctld.log"
slurm_compute_log_file: "/var/log/slurm/slurmd.log"
slurm_debug_flags: "Backfill,BackfillMap,Priority"
slurm_log_file_format: "2"

# State and spool directories
slurm_state_save_location: "/var/lib/slurm"
slurm_spool_dir: "/var/spool/slurmd"
slurm_user: "slurm"

# Job limits
slurm_max_job_count: 10000
slurm_max_array_size: 1000000
slurm_max_step_count: 40000
slurm_min_job_age: 300
slurm_max_job_time: "UNLIMITED"

# Timeout configurations
slurm_message_timeout: 10
slurm_tcp_timeout: 2
slurm_tree_width: 50
slurm_unkillable_step_timeout: 60
slurm_vsize_factor: 0
slurm_wait_time: 0

# Partition configuration
slurm_default_partition: "compute"
slurm_compute_nodes: "compute-[01-99]"
slurm_default_partition_default: "YES"
slurm_partition_max_time: "INFINITE"
slurm_partition_state: "UP"

# GPU partition configuration (when GPUs are available)
slurm_gpu_partition: "gpu"
slurm_gpu_nodes: "compute-[01-99]"
slurm_gpu_partition_default: "NO"
slurm_gpu_partition_max_time: "INFINITE"
slurm_gpu_partition_state: "UP"
slurm_gpu_allow_groups: "ALL"

# Node configuration
slurm_node_sockets: 1
slurm_node_cores_per_socket: 8
slurm_node_threads_per_core: 2
slurm_node_state: "UNKNOWN"

# Controller node configuration
slurm_controller_sockets: 1
slurm_controller_cores_per_socket: 4
slurm_controller_threads_per_core: 2
slurm_controller_state: "UNKNOWN"

# Container integration
slurm_container_integration: false
slurm_constrain_devices: "yes"
slurm_constrain_ram_space: "yes"
slurm_constrain_swap_space: "no"
slurm_constrain_cores: "yes"

# Task 013: Container plugin configuration
slurm_container_enabled: true
# Note: container_singularity.so is not available in standard SLURM packages
# Using general container plugins that are actually available
slurm_container_plugin_path: "/usr/lib/x86_64-linux-gnu/slurm-wlm/job_container_tmpfs.so"

# Singularity/Apptainer configuration
singularity_runtime_path: "/usr/bin/apptainer"
singularity_enable_overlay: "true"
singularity_enable_gpu: "true"
singularity_enable_nv: "true"
singularity_mount_home: "true"
singularity_mount_tmp: "true"
singularity_mount_sys: "false"
singularity_mount_proc: "false"
singularity_mount_dev: "false"
singularity_image_path: "/opt/containers"
singularity_allow_suid: "false"
singularity_contain: "true"
singularity_writable: "false"
singularity_userns: "false"
singularity_network: "none"
singularity_tmpfs: "true"
singularity_debug: "false"
singularity_verbose: "false"
singularity_cleanup: "true"
singularity_gpu_device_access: "yes"
singularity_gpu_isolation: "auto"

# Container bind paths (additional mounts)
singularity_bind_paths: []
  # Example:
  # - "/data:/data:ro"
  # - "/scratch:/scratch"

# Container environment variables
singularity_env_vars: []
  # Example:
  # - "CUDA_VISIBLE_DEVICES=0,1"
  # - "OMP_NUM_THREADS=4"

# Container registries
singularity_registries: []
  # Example:
  # - "docker://registry.hub.docker.com"
  # - "shub://singularity-hub.org"

# Plugin stack configuration
slurm_job_submit_plugins: []
slurm_site_factor_plugins: []
slurm_auth_alt_plugins: []
slurm_cred_plugins: []

# Power management
slurm_power_management: false
slurm_power_plugin: "power/none"
slurm_power_parameters: ""

# Checkpoint configuration
slurm_job_checkpoint_dir: "/var/checkpoint"

# SLURM Controller Package Installation
slurm_controller_packages:
  - slurm-wlm              # Core SLURM workload manager
  - slurm-wlm-doc          # Documentation
  - slurmdbd               # Database daemon for accounting
  - slurm-client           # Client tools
  - munge                  # Authentication daemon
  - libmunge2              # MUNGE runtime library
  - libmunge-dev           # Development libraries
  - mariadb-server         # Database backend
  - libmariadb-dev         # Database client libraries
  - libpmix2               # PMIx for MPI integration
  - libpmix-dev            # PMIx development headers

# Task 013: Container runtime packages
# Note: Container runtime may need to be installed from external repositories
# Common package names: singularity, apptainer, singularity-ce
slurm_controller_container_packages:
  - squashfs-tools         # Required for container image creation
  - cryptsetup-bin         # Required for encryption support
  - fuse                   # Required for overlay filesystems

# Container runtime installation method
# Options: "package" (from repo), "external" (from external source), "skip" (manual installation)
container_install_method: "skip"

# Alternative container runtime packages to try (uncomment as needed)
# slurm_controller_container_runtime_packages:
#   - apptainer            # Apptainer (if available in repos)
#   - singularity          # Singularity (if available in repos)

# Package installation settings
slurm_package_state: "present"
slurm_update_cache: true
slurm_cache_valid_time: 3600

# Build and deployment settings
packer_build: false
install_database: true
install_monitoring_stack: true
hpc_node_type: "controller"
