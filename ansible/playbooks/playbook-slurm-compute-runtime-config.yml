---
# SLURM Compute Runtime Configuration Playbook
# Task 022: Runtime configuration playbook for SLURM compute node
# This playbook is specifically for runtime deployment and testing
# Usage:
#   ansible-playbook -i inventory playbook-slurm-compute-runtime-config.yml

- name: SLURM Compute Node Runtime Configuration
  hosts: "{{ target_hosts | default('all') }}"
  become: true
  gather_facts: true

  vars:
    # Runtime deployment mode (not a Packer build)
    packer_build: false
    hpc_node_type: "compute"

    # SLURM compute configuration
    slurm_compute_enabled: true
    slurm_container_enabled: true

    # Controller connection (override in inventory or extra-vars)
    slurm_controller_host: "{{ groups['controller'][0] | default('controller') }}"
    slurm_controller_port: 6817

  pre_tasks:
    - name: Verify this is runtime mode
      assert:
        that:
          - not (packer_build | bool)
        fail_msg: "This playbook is for runtime deployment only. packer_build must be false."
        success_msg: "Runtime deployment mode confirmed."

    - name: Check if slurmd is installed
      command: which slurmd
      register: slurmd_check
      changed_when: false
      failed_when: false

    - name: Display installation status
      debug:
        msg: |
          SLURM Compute Node Runtime Configuration:
          - Target hosts: {{ target_hosts | default('all') }}
          - Node type: {{ hpc_node_type }}
          - Controller host: {{ slurm_controller_host }}
          - slurmd installed: {{ 'Yes' if slurmd_check.rc == 0 else 'No' }}

  roles:
    - role: slurm-compute
      vars:
        packer_build: false

  post_tasks:
    - name: Verify slurmd service is running
      systemd:
        name: slurmd
        state: started
      register: slurmd_service_status
      become: true

    - name: Check node registration with controller
      shell: |
        timeout 30 bash -c 'until scontrol show node {{ inventory_hostname }} 2>/dev/null | grep -q "State="; do sleep 2; done'
      register: node_registration
      changed_when: false
      failed_when: false

    - name: Display node state
      command: scontrol show node {{ inventory_hostname }}
      register: node_state
      changed_when: false
      failed_when: false
      when: node_registration.rc == 0

    - name: Verify container runtime availability
      shell: |
        if command -v apptainer >/dev/null 2>&1; then
          echo "apptainer"
          apptainer --version
        elif command -v singularity >/dev/null 2>&1; then
          echo "singularity"
          singularity --version
        else
          echo "none"
        fi
      register: container_runtime_check
      changed_when: false
      when: slurm_container_enabled | bool

    - name: Test simple SLURM job submission
      command: srun -N1 hostname
      register: test_job
      changed_when: false
      failed_when: false
      when: node_registration.rc == 0

    - name: Display runtime configuration results
      debug:
        msg: |
          SLURM Compute Node Runtime Configuration Complete:
          - Hostname: {{ inventory_hostname }}
          - slurmd service: {{ 'Running' if slurmd_service_status.state == 'started' else 'Failed' }}
          - Node registration: {{ 'SUCCESS' if node_registration.rc == 0 else 'FAILED' }}
          {% if node_registration.rc == 0 %}
          - Node state: {{ node_state.stdout | regex_search('State=\S+') if node_state.rc == 0 else 'Unknown' }}
          - Test job result: {{ 'SUCCESS - ' + test_job.stdout if test_job.rc == 0 else 'FAILED' if test_job.rc is defined else 'Not tested' }}
          {% endif %}
          {% if slurm_container_enabled | bool %}
          - Container runtime: {{ container_runtime_check.stdout.split('\n')[0] if container_runtime_check.rc == 0 else 'Not available' }}
          {% endif %}

    - name: Display troubleshooting information on failure
      debug:
        msg: |
          Node registration failed. Troubleshooting steps:
          1. Check MUNGE service: systemctl status munge
          2. Verify MUNGE key matches controller
          3. Check network connectivity to controller: {{ slurm_controller_host }}
          4. Review slurmd logs: tail -f /var/log/slurm/slurmd.log
          5. Verify slurm.conf has correct controller hostname
          6. Check firewall rules allowing SLURM traffic
      when: node_registration.rc != 0

    - name: Fail if node failed to register
      fail:
        msg: |
          SLURM compute node failed to register with controller.
          Please check the troubleshooting steps above.
      when:
        - node_registration.rc != 0
        - fail_on_registration_error | default(false) | bool
