---
# HPC Compute Playbook
# Specialized playbook for SLURM compute nodes with GPU support and container runtime
# Usage:
#   Packer: ansible-playbook -e packer_build=true -e hpc_node_type=compute playbook-hpc-compute.yml
#   Live:   ansible-playbook -i inventory playbook-hpc-compute.yml

- name: Deploy HPC Compute Node with SLURM and GPU Support
  hosts: "{{ target_hosts | default('all') }}"
  become: true
  gather_facts: true

  vars:
    # Packer build detection and configuration
    packer_build: "{{ packer_build | default(false) }}"
    hpc_node_type: "{{ hpc_node_type | default('compute') }}"

    # Compute-specific installation flags
    install_slurm_compute: "{{ install_slurm_compute | default(true) }}"
    install_container_runtime: "{{ install_container_runtime | default(true) }}"
    install_gpu_support: "{{ install_gpu_support | default(true) }}"

    # NVIDIA GPU Configuration
    nvidia_install_cuda: "{{ nvidia_install_cuda | default(false) }}"
    nvidia_packer_build: "{{ packer_build | default(false) }}"

    # SLURM Configuration
    slurm_version: "23.11.4"
    slurm_gpu_enabled: "{{ install_gpu_support | default(true) }}"
    slurm_container_enabled: "{{ install_container_runtime | default(true) }}"

    # Container Runtime Configuration
    container_runtime_type: "apptainer"  # Apptainer is the successor to Singularity
    container_runtime_version: "1.4.2"
    container_runtime_install_method: "github"  # Use GitHub releases
    container_runtime_enable_service: false  # Don't start service in Packer builds

  roles:
    - hpc-base-packages
    - container-runtime
    - nvidia-gpu-drivers  # GPU support for compute nodes
    - slurm-compute      # SLURM compute daemon and configuration

  tasks:
    - name: Verify HPC base packages installation
      debug:
        msg: "HPC base packages have been installed successfully"

    - name: Verify container runtime installation
      command: "{{ container_runtime_binary | default('apptainer') }} --version"
      register: container_runtime_version_check
      changed_when: false
      failed_when: false
      when: install_container_runtime | bool

    - name: Display container runtime version
      debug:
        msg: "Container runtime {{ container_runtime_binary | default('apptainer') }} version: {{ container_runtime_version_check.stdout }}"
      when:
        - install_container_runtime | bool
        - container_runtime_version_check.rc == 0

    - name: Verify NVIDIA driver installation
      shell: "nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits"
      register: nvidia_driver_version
      changed_when: false
      failed_when: false
      when: install_gpu_support | bool

    - name: Display NVIDIA driver version
      debug:
        msg: "NVIDIA driver version: {{ nvidia_driver_version.stdout }}"
      when:
        - install_gpu_support | bool
        - nvidia_driver_version.rc == 0

    - name: Verify SLURM compute installation
      command: "{{ item }}"
      register: slurm_compute_check
      changed_when: false
      failed_when: false
      loop:
        - "slurmd -V"
        - "sinfo --version"
      when: install_slurm_compute | bool

    - name: Display SLURM compute version
      debug:
        msg: "SLURM component {{ item.item }} version: {{ item.stdout.split('\n')[0] }}"
      loop: "{{ slurm_compute_check.results }}"
      when:
        - install_slurm_compute | bool
        - item.rc == 0

    - name: Display deployment context
      debug:
        msg: |
          HPC Compute Node Deployment Context:
          - Packer Build: {{ packer_build }}
          - Node Type: {{ hpc_node_type }}
          - SLURM Compute: {{ install_slurm_compute }}
          - Container Runtime: {{ install_container_runtime }}
          - GPU Support: {{ install_gpu_support }}
          - NVIDIA CUDA: {{ nvidia_install_cuda }}
          - SLURM Version: {{ slurm_version }}
          - Container Runtime: {{ container_runtime_type | default('apptainer') }}
          - Target Hosts: {{ target_hosts | default('all') }}

    - name: Gather installed package facts
      package_facts:
        manager: auto

    - name: Display relevant installed packages
      debug:
        msg: "{{ ansible_facts.packages | dict2items | selectattr('key', 'in', ['tmux', 'htop', 'vim', 'curl', 'wget', 'nvidia-driver', 'fuse', 'squashfs-tools', 'uidmap', 'slurm-wlm', 'slurmd', 'munge']) | list }}"
