---
# HPC Compute Playbook
# Specialized playbook for SLURM compute nodes with GPU support and container runtime
# Usage:
#   Packer: ansible-playbook -e packer_build=true -e hpc_node_type=compute playbook-hpc-compute.yml
#   Live:   ansible-playbook -i inventory playbook-hpc-compute.yml

- name: Deploy HPC Compute Node with SLURM and GPU Support
  hosts: "{{ target_hosts | default('all') }}"
  become: true
  gather_facts: true

  vars:
    # Node type configuration
    hpc_node_type: "compute"

    # Compute-specific installation flags with defaults
    # These can be overridden by inventory variables or --extra-vars
    # Default to true for all compute features unless explicitly disabled
    _install_slurm_compute: "{{ install_slurm_compute | default(true) }}"
    _install_container_runtime: "{{ install_container_runtime | default(true) }}"
    _install_gpu_support: "{{ install_gpu_support | default(true) }}"
    _install_monitoring_stack: "{{ install_monitoring_stack | default(true) }}"

    # Monitoring configuration for compute nodes (Node Exporter only)
    monitoring_role: "{{ 'node' if (_install_monitoring_stack | bool) else 'none' }}"

    # NVIDIA GPU Configuration
    nvidia_install_cuda: "{{ install_gpu_support | default(false) }}"
    nvidia_packer_build: "{{ packer_build | default(false) }}"

    # SLURM Configuration
    slurm_version: "23.11.4"
    slurm_gpu_enabled: "{{ install_gpu_support | default(true) }}"
    slurm_container_enabled: "{{ install_container_runtime | default(true) }}"

    # Container Runtime Configuration
    container_runtime_type: "apptainer"  # Apptainer is the successor to Singularity
    container_runtime_version: "1.4.2"
    container_runtime_install_method: "github"  # Use GitHub releases
    container_runtime_enable_service: false  # Don't start service in Packer builds

  roles:
    - hpc-base-packages
    - container-runtime
    - role: monitoring-stack
      vars:
        monitoring_role: "node"
      when: install_monitoring_stack | default(true) | bool
    - nvidia-gpu-drivers  # GPU support for compute nodes
    - slurm-compute      # SLURM compute daemon and configuration

  tasks:
    - name: Verify HPC base packages installation
      debug:
        msg: "HPC base packages have been installed successfully"

    - name: Verify container runtime installation
      command: "{{ container_runtime_binary | default('apptainer') }} --version"
      register: container_runtime_version_check
      changed_when: false
      failed_when: false
      when: _install_container_runtime | bool

    - name: Display container runtime version
      debug:
        msg: "Container runtime {{ container_runtime_binary | default('apptainer') }} version: {{ container_runtime_version_check.stdout }}"
      when:
        - _install_container_runtime | bool
        - container_runtime_version_check.rc == 0

    - name: Verify NVIDIA driver installation
      shell: "nvidia-smi --query-gpu=driver_version --format=csv,noheader,nounits"
      register: nvidia_driver_version
      changed_when: false
      failed_when: false
      when: _install_gpu_support | bool

    - name: Display NVIDIA driver version
      debug:
        msg: "NVIDIA driver version: {{ nvidia_driver_version.stdout }}"
      when:
        - _install_gpu_support | bool
        - nvidia_driver_version.rc == 0

    - name: Verify SLURM compute installation
      command: "{{ item }}"
      register: slurm_compute_check
      changed_when: false
      failed_when: false
      loop:
        - "slurmd -V"
        - "sinfo --version"
      when: _install_slurm_compute | bool

    - name: Display SLURM compute version
      debug:
        msg: "SLURM component {{ item.item }} version: {{ item.stdout.split('\n')[0] }}"
      loop: "{{ slurm_compute_check.results }}"
      when:
        - _install_slurm_compute | bool
        - item.rc == 0

    - name: Verify monitoring stack installation (Node Exporter)
      command: "prometheus-node-exporter --version"
      register: node_exporter_check
      changed_when: false
      failed_when: false
      when: install_monitoring_stack | bool

    - name: Display Node Exporter version
      debug:
        msg: "Node Exporter version: {{ node_exporter_check.stdout.split('\n')[0] }}"
      when:
        - install_monitoring_stack | bool
        - node_exporter_check.rc == 0

    - name: Display deployment context
      debug:
        msg: |
          HPC Compute Node Deployment Context:
          - Packer Build: {{ packer_build }}
          - Node Type: {{ hpc_node_type }}
          - SLURM Compute: {{ install_slurm_compute }}
          - Container Runtime: {{ install_container_runtime }}
          - GPU Support: {{ install_gpu_support }}
          - Monitoring Stack: {{ install_monitoring_stack }}
          - Monitoring Role: {{ monitoring_role | default('none') }}
          - NVIDIA CUDA: {{ nvidia_install_cuda }}
          - SLURM Version: {{ slurm_version }}
          - Container Runtime: {{ container_runtime_type | default('apptainer') }}
          - Target Hosts: {{ target_hosts | default('all') }}

    - name: Gather installed package facts
      package_facts:
        manager: auto

    - name: Display relevant installed packages
      debug:
        msg: "{{ ansible_facts.packages | dict2items | selectattr('key', 'in', ['tmux', 'htop', 'vim', 'curl', 'wget', 'nvidia-driver', 'fuse', 'squashfs-tools', 'uidmap', 'slurm-wlm', 'slurmd', 'munge', 'prometheus-node-exporter']) | list }}"
